{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "def print_full_rows(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    return x\n",
    "    pd.reset_option('display.max_rows')\n",
    "    \n",
    "def print_full_columns(x):\n",
    "    pd.set_option('display.max_columns', len(x.columns))\n",
    "    return x\n",
    "    pd.reset_option('display.max_rows')"
   ]
  },
  {
   "source": [
    "### Concatenating all 2019 Data "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df_2019 = pd.read_csv('loandata_2019.csv')"
   ]
  },
  {
   "source": [
    "### Preprocessing the data\n",
    "\n",
    "1. Dropping the values with more than 50% Missing values\n",
    "2. Remove features that are not identifiable before issuing a loan\n",
    "3. Convert Categorical variables / Log scale \n",
    "4. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = loan_df_2019.copy()"
   ]
  },
  {
   "source": [
    "### Only using two binary state of the loan status"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id', 'member_id', 'loan_amnt', 'funded_amnt',\n",
       "       'funded_amnt_inv', 'term', 'int_rate', 'installment', 'grade',\n",
       "       ...\n",
       "       'orig_projected_additional_accrued_interest',\n",
       "       'hardship_payoff_balance_amount', 'hardship_last_payment_amount',\n",
       "       'debt_settlement_flag', 'debt_settlement_flag_date',\n",
       "       'settlement_status', 'settlement_date', 'settlement_amount',\n",
       "       'settlement_percentage', 'settlement_term'],\n",
       "      dtype='object', length=151)"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['loan_status'].isin(['Fully Paid', 'Charged Off'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_values(df):\n",
    "        mis_val = df.isnull().sum()\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        print (\"Dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataframe has 151 columns.\nThere are 61 columns that have missing values.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                       Missing Values  % of Total Values\n",
       "member_id                      118985              100.0\n",
       "next_pymnt_d                   118985              100.0\n",
       "desc                           118985              100.0\n",
       "settlement_percentage          118125               99.3\n",
       "settlement_amount              118125               99.3\n",
       "...                               ...                ...\n",
       "last_pymnt_d                      863                0.7\n",
       "dti                               296                0.2\n",
       "revol_util                        185                0.2\n",
       "all_util                           32                0.0\n",
       "avg_cur_bal                        12                0.0\n",
       "\n",
       "[61 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Missing Values</th>\n      <th>% of Total Values</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>member_id</th>\n      <td>118985</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>next_pymnt_d</th>\n      <td>118985</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>desc</th>\n      <td>118985</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>settlement_percentage</th>\n      <td>118125</td>\n      <td>99.3</td>\n    </tr>\n    <tr>\n      <th>settlement_amount</th>\n      <td>118125</td>\n      <td>99.3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>last_pymnt_d</th>\n      <td>863</td>\n      <td>0.7</td>\n    </tr>\n    <tr>\n      <th>dti</th>\n      <td>296</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>revol_util</th>\n      <td>185</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>all_util</th>\n      <td>32</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>avg_cur_bal</th>\n      <td>12</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>61 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "null_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['annual_inc_joint', 'debt_settlement_flag_date', 'deferral_term', 'desc', 'dti_joint', 'hardship_amount', 'hardship_dpd', 'hardship_end_date', 'hardship_last_payment_amount', 'hardship_length', 'hardship_loan_status', 'hardship_payoff_balance_amount', 'hardship_reason', 'hardship_start_date', 'hardship_status', 'hardship_type', 'member_id', 'mths_since_last_delinq', 'mths_since_last_major_derog', 'mths_since_last_record', 'mths_since_recent_bc_dlq', 'mths_since_recent_revol_delinq', 'next_pymnt_d', 'orig_projected_additional_accrued_interest', 'payment_plan_start_date', 'revol_bal_joint', 'sec_app_chargeoff_within_12_mths', 'sec_app_collections_12_mths_ex_med', 'sec_app_earliest_cr_line', 'sec_app_fico_range_high', 'sec_app_fico_range_low', 'sec_app_inq_last_6mths', 'sec_app_mort_acc', 'sec_app_mths_since_last_major_derog', 'sec_app_num_rev_accts', 'sec_app_open_acc', 'sec_app_open_act_il', 'sec_app_revol_util', 'settlement_amount', 'settlement_date', 'settlement_percentage', 'settlement_status', 'settlement_term', 'verification_status_joint']\n"
     ]
    }
   ],
   "source": [
    "missing_frac = df.isnull().mean()\n",
    "drop_list = sorted(missing_frac[missing_frac >= 0.50].index)\n",
    "print(drop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_cols(cols):\n",
    "    df.drop(labels=cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols(drop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(118985, 107)"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list2 = ['acc_now_delinq', 'acc_open_past_24mths', 'avg_cur_bal', 'bc_open_to_buy', 'bc_util', 'chargeoff_within_12_mths', 'collection_recovery_fee', 'collections_12_mths_ex_med', 'debt_settlement_flag', 'delinq_2yrs', 'delinq_amnt', 'funded_amnt', 'funded_amnt_inv', 'hardship_flag', 'inq_last_6mths', 'last_credit_pull_d', 'last_fico_range_high', 'last_fico_range_low', 'last_pymnt_amnt', 'last_pymnt_d', 'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl', 'mths_since_recent_bc', 'mths_since_recent_inq', 'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl', 'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl', 'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats', 'num_tl_120dpd_2m', 'num_tl_30dpd', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m',  'out_prncp', 'out_prncp_inv', 'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'pymnt_plan', 'recoveries', 'tax_liens', 'tot_coll_amt', 'tot_cur_bal', 'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit', 'total_il_high_credit_limit', 'total_pymnt', 'total_pymnt_inv', 'total_rec_int', 'total_rec_late_fee', 'total_rec_prncp', 'total_rev_hi_lim']\n",
    "\n",
    "drop_cols(drop_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols(['id','grade','emp_title','title','zip_code','policy_code', 'url','open_acc_6m', 'open_act_il', 'open_il_12m','open_il_24m', 'mths_since_rcnt_il', 'total_bal_il', 'il_util','open_rv_12m','open_rv_24m','open_rv_24m','max_bal_bc','all_util','inq_fi','total_cu_tl','inq_last_12m'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the term feature\n",
    "df['term'].sample(5)\n",
    "df['term'] = df['term'].apply(lambda s: np.int8(s.split()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "48977     10.0\n",
       "202107     1.0\n",
       "133872     0.0\n",
       "433519    10.0\n",
       "416341     NaN\n",
       "Name: emp_length, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "# Fix the emp_length feature (convert to integer)\n",
    "df['emp_length'].replace('10+ years', '10 years', inplace=True)\n",
    "df['emp_length'].replace('< 1 year', '0 years', inplace=True)\n",
    "df['emp_length'].value_counts(dropna=False).sort_index()\n",
    "df.emp_length.map( lambda x: str(x).split()[0]).value_counts(dropna=True).sort_index()\n",
    "df['emp_length'] = df.emp_length.map(lambda x: float(str(x).split()[0]))\n",
    "df['emp_length'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the int_rate feature\n",
    "df['int_rate'].replace(regex=True, inplace=True, to_replace=r'%', value=r'')\n",
    "df['int_rate'] = df['int_rate'].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the annual income variable, use log-transform since there is a large range of variation, we log-transform the values.\n",
    "df['annual_inc'] = df['annual_inc'].apply(lambda x:np.log10(x+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(118985,)"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "# fix earliest_cr_line to datetime variable\n",
    "from datetime import datetime\n",
    "\n",
    "df.earliest_cr_line = pd.to_datetime(df.earliest_cr_line)\n",
    "dttoday = datetime.now().strftime('%Y-%m-%d')\n",
    "df.earliest_cr_line = df.earliest_cr_line.apply(lambda x:(np.timedelta64((x - pd.Timestamp(dttoday)),'D').astype(int))/-365)\n",
    "df.earliest_cr_line.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new variable fico_score, which is the mean value of fico_low and fico_high\n",
    "df['fico_score'] = (df['fico_range_low'] + df['fico_range_high'])/2.\n",
    "drop_cols(['fico_range_high','fico_range_low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the bin width of pub_rec\n",
    "df.pub_rec = df.pub_rec.map(lambda x: 3 if x >2.0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix revol_bal\n",
    "df['revol_bal'] = df['revol_bal'].apply(lambda x:np.log10(x+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix revol_util\n",
    "df['revol_util'] = df['revol_util'].replace(regex=True, inplace=False, to_replace=r'%', value=r'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['revol_util'] = df['revol_util'].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(118985, 28)"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "# Change target variable to be a binary variable. Fully Paid = 0, Charged Off = 1\n",
    "df['Charged_Off'] = df['loan_status'].apply(lambda s: np.float(s == 'Charged Off'))\n",
    "drop_cols('loan_status')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(118985, 23)"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "# drop columns that are not linearly correlated with the target variable. \n",
    "drop_cols(['installment', 'mo_sin_old_rev_tl_op','total_acc','pub_rec_bankruptcies', 'issue_d'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_list =['sub_grade','home_ownership','verification_status','purpose','addr_state','initial_list_status','application_type']\n",
    "df[dummy_list].isnull().any()\n",
    "df = pd.get_dummies(df, columns=dummy_list, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "97048"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "df['Charged_Off'].value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.8156322225490608, 0.18436777745093919)"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "fully_paid = (df['Charged_Off'].value_counts()[0])/len(df)\n",
    "charged_off = (df['Charged_Off'].value_counts()[1])/len(df)\n",
    "(fully_paid, charged_off)\n"
   ]
  },
  {
   "source": [
    "# Modeling Begin"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "X = df.drop('Charged_Off', axis =1)\n",
    "y = df['Charged_Off']"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 75,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(118985, 118985)"
      ]
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "source": [
    "(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0    97048\n",
       "0.0    97048\n",
       "Name: Charged_Off, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.9140219272937103,\n",
       " 0.8868807188195532,\n",
       " 0.8740274940903772,\n",
       " 0.8876156661955668)"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "clf = RandomForestClassifier(max_depth = 20)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "train_score = clf.score(X_train_scaled, y_train)\n",
    "test_score = clf.score(X_test_scaled, y_test)\n",
    "\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "f1_score = f1_score(y_test, y_pred)\n",
    "roc_score = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "(train_score, test_score, f1_score, roc_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "clf = RandomForestClassifier(max_depth = 20)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "train_score = clf.score(X_train_scaled, y_train)\n",
    "test_score = clf.score(X_test_scaled, y_test)\n",
    "\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "f1_score = f1_score(y_test, y_pred)\n",
    "roc_score = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "(train_score, test_score, f1_score, roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import f1_score\n",
    "# from numpy import mean\n",
    "# from sklearn.datasets import make_classification\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "# from imblearn.pipeline import Pipeline\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# steps = [('over', SMOTE()), ('model', RandomForestClassifier(max_depth=20))]\n",
    "# pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# scores = cross_val_score(pipeline, X_train_scaled, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.6169386970021707,\n",
       " 0.6137581403017064,\n",
       " 0.4995727865000533,\n",
       " 0.6153383680274674)"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "train_score = clf.score(X_train_scaled, y_train)\n",
    "test_score = clf.score(X_test_scaled, y_test)\n",
    "\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "f1_score = f1_score(y_test, y_pred)\n",
    "roc_score = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "(train_score, test_score, f1_score, roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# clf = KNeighborsClassifier()\n",
    "# clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# train_score = clf.score(X_train_scaled, y_train)\n",
    "# test_score = clf.score(X_test_scaled, y_test)\n",
    "\n",
    "# y_pred = clf.predict(X_test_scaled)\n",
    "# f1_score = f1_score(y_test, y_pred)\n",
    "\n",
    "# (train_score, test_score, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.6580592421619542, 0.657406644134861, 0.6694372638695565, 0.6571895300978172)"
      ]
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "train_score = clf.score(X_train_scaled, y_train)\n",
    "test_score = clf.score(X_test_scaled, y_test)\n",
    "\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "f1_score = f1_score(y_test, y_pred)\n",
    "roc_score = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "(train_score, test_score, f1_score, roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.8724067815239195, 0.8749690874618745, 0.862808945571309, 0.8756123805775446)"
      ]
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "clf = AdaBoostClassifier()\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "train_score = clf.score(X_train_scaled, y_train)\n",
    "test_score = clf.score(X_test_scaled, y_test)\n",
    "\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "f1_score = f1_score(y_test, y_pred)\n",
    "\n",
    "roc_score = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "(train_score, test_score, f1_score, roc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.884531365922018, 0.8601104608029017, 0.8449732791303157, 0.8608143161322245)"
      ]
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth = 20)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "train_score = clf.score(X_train_scaled, y_train)\n",
    "test_score = clf.score(X_test_scaled, y_test)\n",
    "\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "f1_score = f1_score(y_test, y_pred)\n",
    "roc_score = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "(train_score, test_score, f1_score, roc_score)\n"
   ]
  },
  {
   "source": [
    "# GridSearching RandomForest and AdaBoost    "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(194096, 114)"
      ]
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [5, 20, 50, 100]\n",
    "    \n",
    "}\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "train_score = clf.score(X_train_scaled, y_train)\n",
    "test_score = clf.score(X_test_scaled, y_test)\n",
    "\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "f1_score = f1_score(y_test, y_pred)\n",
    "roc_score = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "(train_score, test_score, f1_score, roc_score)"
   ]
  }
 ]
}